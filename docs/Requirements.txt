Gazebo2 or Cluster Test Handler (CLTH) Functional Requirements
Ver 1.4


1. Functionality exists in current version of Gazebo and is to be continued.
-----------


1.1  Runs as a user process.  Gracefully handles permissions to support multiple users running out of the same installation space.   
1.2  Placeholders for results created immediately upon launch
1.3 Supports a continual testing mode
1.4 Supports testing at a targeted load level
1.5 Supports a delay time between test suite launches
1.6 Defined convention to automate data collection of test outputs (for example, current trend data tags)
1.7 Maintains enough data and provides tools to generate system coverage statistics
1.8 Maintains enough data and provides tools to generate individual test run-time stats.
1.9 Maintains enough data and provides tools for summarizing passing and failing results with runtime statistics
1.10 Supports efficient time based analysis (user selectable results to any time frame)  
1.11 Hierarchical directory store for raw data to facilite easy accss to results



2. Exists in some form now, but needs improvements/enhancements
---------

2.1 Support for Moab and other schedulers/resource manager combinations.
2.2 Support for running simultaneous single or multiple test suites.  
2.3 Support for targeting nodes and segments, where possible.  
2.4 Minimize job launch script footprint called from DRM
2.5 Support run-time test instance copy to new run location (is default now) 
2.6 Supports build and then run mode, as well as running existing binaries
2.7 Support pre-run of resource availability before launch ( i.e. - go/no-go decision to run based on available file space )
2.8 Better user documentation / developer documentation
2.9 Provide solid generic test code(s) (gcc based?) as example(s).
2.10 Generation tools of baseline trend data 
2.11 Performance learning capability to determine threshold for pass/fail. (Polish work done by Evan) 
2.12 Summary result reporting ( what more?)
2.13 Automated fail analysis reporting based on known failures (knowledge based analysis)
2.14 Automated performance data summaries and charting
2.15 Simpler design for making it easy to add tests



3. New Requirements
------------
 
3.1 Support multiple test managers running simultaneously (continuous launching tool)
3.2 Support multiple master test suite configuration file for feeding a variety of parameters to tests.  
3.3 Support testing front-ends as well as compute nodes thus facilitating testing fta's too
3.4 Elegant way of handling combinatorial parameter studies. 
3.5 Mechanism to hook in measurement/profiling tools ( power aware, LDMS, sensors, I/O, profiling, fingerprinting )   
3.6 Support multiple compilers libraries and optimization levels and flags for one test instance, not requiring new test directories (same as # 10 ??)
3.7 GUI job monitoring / launching / results analysis mechanism
3.8 Singular command line interface providing comprehensive list of features
3.9 System component discovery mechanism (both hardware and software) with autopopulation of main config file where appropriate.
3.10 Modular design/architecture for ease of co-development the harness.
3.11 Functions have self test or unit test built-in for regression test verification. 
