# YAML        

#   Default test configuration file, vers. 0.2 

# NOTE - all CAPS variable are env vars

#    All entires can be re-defined by a users test config
#    file (found in PV_HOME/test_conf) with defaults inherited
#    from this file.
#    In theory, the entire default file can be used, but we recommend
#    making a copy, editing at least the name, location, and
#    runcmd sub-elements and removing everything else you don't need.
#

# for YAML formatting issues try: http://yaml-online-parser.appspot.com
    
#    All values are available through:
#     -   YamlTestConfig class interface 

 
# A new named stanza is needed for each new test,
# but you only need to change what is different from the
# default testSuite config file

# Default testSuite override.
# Uncomment and place in User defined testSuite with
# a fully qualified path/name or just name of the file.
# DefaultTestSuite: default_test_suite.yaml

# UNIQUE test/job identifier. Any string will do.
UniqueTestName:

  # uri of test  
  source_location: HOME
        
  # Build Section  
  build:
    # command is relative to source directory
    cmd: 'buildme'
    build_before_run_flag : False
        
  # Run Section 
  run:
     cmd: 'runme'
     # select one scheduler type, or make a new one  
     # choices can be moab, slurm, torque, none  
     scheduler: 'moab'
     # user specified test specific argument string
     test_args: '' 
     # number of times to repeat
     count: 1

  # Optional scheduler section needed if defined in Run section
  moab:

     # Parameter(s) provided to scheduler
     # Element stanza corresponds to scheduler choice above.
     # All combinations of <num_nodes> and <procs_per_node> will be
     # tried by by the scheduler where it makes sense. A "none"
     # choice simply invokes the run command once

     # comma separated list of values, or range 
     num_nodes: 1
     # queue to submit jobs against
     queue: '' 
     # comma separated list of values, or range 
     procs_per_node: 16
     # time in hr::min::secs
     time_limit: 01:00:00
     # free formatted string added to msub invocation line
     msub_args:
     # optional target segment, will be added to feature argument
     target_seg: ''

  # Working space section
  # The default is to create a working space to run each job.
  # If changed to a null value ("") then none created, otherwise
  # it should be relative to the source directory or a
  # fully specified directory.

  working_space:
    path: 'pv_ws' 
    copy_to_ws: ''
    save_from_ws: ''
    no_copy: '*.c,*.o,*.h'


  # Results section
  results:

    # The test handler places all results under this directory.
    root: '/Users/cwi/pv_results'

    # Pass or Fail matching pattern
    # the test handler will try to match "<result> pass" or
    # <result> fail" to determine if the test passed or failed.
    pass_fail_regex: '<result\w{0,1}>\s*(.+)'

    # Trend Data matching pattern
    # the test handler will try to match "<td> name value units"
    # to discover any special result data  (a.k.a - trend data).
    # The "units" field is optional.
    trend_data_regex: <td>\s+(.*)

    # Script called at the end of the job. By default, the test harness requires
    # a "<result>" entry in the job output log file at the beginning of a line
    # followed by a pass or fail. Of course, there are many ways to accomplish this,
    # but if it's not done by the job itself this may be a convient way to add
    # this entry.
    # If defined here and executable, call...  
    epilog_script: "" 

    ##### TO BE MOVED (???) TO "generic" config file!
    # Script that contains the logic that examines the job log 
    # to see if the test passed or failed.  chk_pf reports
    # a fail if there are any "fail" matches with the
    # pass_fail_regex, OR it can report pass if at least one "pass"
    # is matched with the regex, otherwise unknown is reported.
    pass_fail_logic: $TH_BIN/chk_pf

  ldms:
    # to be set to env var LDMS_HOME
    install_dir : "/usr/projects/hpctools/ldms"
    # command to fire up tool on all nodes
    start_cmd: startJobNodesLDMSD
    # base directory where all output for job resides 
    output_dir_root: HOME 
    # sample rate
    freq: normal
    # comman separated list of plugin sampler names (all coming soon),
    # will be skipped if not supported
    metric_list: "meminfo,vmstat"
    

  time:
    tz: 'US/Mountain'
